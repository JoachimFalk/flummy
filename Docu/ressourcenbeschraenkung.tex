\chapter{\label{konzept}Ressourcenbeschränkung}

Dieses Kapitel beschreibt die Modellierung von Ressourcenbeschränkungen in der 
InfiniBand-HCA-Simulation. Zunächst soll jedoch geklärt werden, was unter
Ressourcenbeschränkung zu verstehen ist und wie dieses effizient in SystemC modellierbar
ist. Die hier vorgestellten Ideen sind \cite{vpc:2005} entnommen.

Bei der Implementierung eines Systems, z.\,B. des 
InfiniBand-Controller, werden ausführende Einheiten benötigt,
z.\,B. Prozessoren oder spezielle Hardware (DSP, ASIC, ASIP).  Selbst ein rein
in Software geschriebenes System benötigt mindestens einen Prozessor zur
Ausführung. Die Anzahl solcher ausführenden Einheiten ist im Allgemeinen
endlich, anders ausgedrückt: Die Zahl der Ressourcen ist
\emph{beschränkt}. Eine Beschränkung von Betriebsmitteln wie Speicher oder
E/A-Peripherie soll nicht Gegenstand der Diskussion sein. 


Den ausführenden Einheiten (Ressourcen) stehen auszuführende Einheiten
(Prozesse, Tasks)\footnote{Die Begriffe \emph{Prozess}, \emph{Task} oder
  \emph{Aufgabe} werden in dieser Studie synonym, als Bezeichnung für
  Tätigkeiten, verwendet.}  gegenüber. Notwendigerweise benötigt
jeder Prozess eine Ressource zur Ausführung. Es besteht jedoch die
Möglichkeit, dass ein Prozess auf unterschiedlichen Ressourcen ausgeführt
werden könnte. Dieser Zusammenhang ist in Abbildung \ref{fig:ib_spec_graph}
dargestellt. Die formale Grundlage für diese Modellierungsform ist in den 
Arbeiten \cite{btt:1998, teich:1997} beschrieben. Folgende Begrifflichkeiten 
werden dabei verwendet:
\begin{description}
\item[Problemgraph:] Ein gerichteter Graph $G_P = (V_P,E_P)$ mit Knotenmenge $V_P$ 
und Kantenmenge $E_P$. Knoten repräsentieren funktionale Aufgaben sowie 
Kommunikationsaufgaben. Kanten stellen gerichtete Datenabhängigkeiten dar.
\item[Architekturgraph:] Ein gerichteter Graph $G_A = (V_A,E_A)$ mit der 
Menge der allozierbaren Komponenten $V_A$ und der Menge der gerichteten 
Kommunikationsverbindungen $E_A$.
\item[Spezifikationsgraph:] Der gerichtete Spezifikationsgraph $G_S = (V_S,E_S)$ besteht aus einem Problemgraphen $G_P = (V_P,E_P)$ und einem Architekturgraphen $G_A = (V_A,E_A)$ und Abbildungskanten $E_M$ mit $V_S = V_P \cup V_A$ und $E_S = E_P \cup E_A \cup E_M$.
\end{description}
Diese Art der Modellierung ermöglicht es, ein Verhalten unabhängig von der zu 
verwendenden Architektur zu beschreiben. Ausgehend von einer Spezifikation können 
unterschiedliche Implementierungen entstehen, welche sich in der \emph{Allokation}
(Auswahl der verwendeten Architekturknoten) und in der \emph{Bindung} von Problemknoten auf 
Architekturknoten unterscheiden. Dadurch ergeben sich unterschiedliche Bewertungen für 
unterschiedliche Implementierungen. Beispielhaft seien hier Chipfläche, 
Latenz und Stromverbrauch genannt. Für die Entscheidung, welche konkrete
Implementierung verwendet werden soll, kann ein Optimierungsverfahren 
eingesetzt werden.

\begin{figure}
\begin{center}
\includegraphics[width=12cm]{ib_spec_graph}
\caption{Spezifikationsgraph: Prozesse aus dem Problemgraphen ($G_P$)
werden mittels Abbildungskanten ($E_M$) auf die Ressourcen des
Architekturgraphen ($G_A$) abgebildet. Eine Abbildung zwischen 
Problemgraph und Architekturgraph kennzeichnet die Ausführbarkeit
eines Prozesses $v_i \in V_P$ auf einer Ressource $v_j \in V_A$.}
\label{fig:ib_spec_graph}
\end{center}
\end{figure} 

Die Leistungsbewertung einer allgemeinen Implementierung ist
nicht trivial. Hier\-für 
eignen sich hervorragend simulative Verfahren zur Average-Case-Bewertung.
Also eine direkte Simulation oder ein Trace-Driven-Simulation 
Verfahren \cite{lrd:2001}. Für die Simulation des InfiniBand-HCA
 wird ein Simulationsframework verwendet, mit dem die 
Ressourcenbeschränkung nachgestellt werden kann. Dieses 
trägt den Namen \emph{Virtual-Processing-Components}-Framework 
(\emph{VPC}-Framework) und wird im Folgenden erläutert.


\section{VPC-Framework}


Ein VPC-Simulator unterscheidet sich wesentlich von üblichen
Befehlssatzsimulatoren oder zyklenakkuraten Simulatoren. Bei diesen wird ein
Programm auf der simulierten Architektur ausgeführt. Der Simulator bildet
dabei eine reale Hardwarekomponente möglichst detailgetreu nach. Derartige
Simulationen sind aufwendig und bieten sich daher nicht für die Simulation komplexer
Systeme an. Eine Simulation auf System\-ebene benötigt entsprechende Einheiten
mit gröberer Granularität. Als Einheiten bieten sich hier zum Beispiel Prozesse
an. Da diese jedoch sehr komplexe Aufgaben darstellen, würde nun wiederum der
Umfang des Simulators explodieren.


Alternativ wird ein System zur Simulation durch entsprechend abstraktere Modelle
dargestellt. Beispiele hierfür sind Petri-Netze \cite{baumgarten:1990}, 
Zustandsautomaten \cite{harel:1987} oder der
oben vorgestellte Problemgraph. Ein solches Modell beschreibt eine Komposition
von Prozessen. Da Implementierungsdetails der Prozesse dabei nicht
betrachtet werden, ist das Zusammenspiel und Zeitverhalten der Prozesse Gegenstand der
Simulation. Dabei geht leider der Bezug zur Architektur (z.\,B. Hardwarekomponenten) 
 verloren. 


Das VPC-Simulationsmodell behält die Trennung von Architektur und Problem
bei. Abbildung \ref{fig:vpc-framework-ueberblick} zeigt eine schematische
Darstellung des Simulationsframeworks. Das Problem wird mit Hilfe von
SystemC-Sprachkonstrukten modelliert. Die Komponenten der Architektur werden
durch virtuelle Komponenten, welche als Objekte in C++ implementiert sind,
dargestellt. Diese virtuellen Komponenten bilden den Kern der Zeitmodellierung im
Simulationsframework. Durch die Mehrzahl von Komponenten
und Prozessen muss eine  Multitasking- und Multiprozessorarchitektur durch das
Framework betrachtet werden. Weiterhin sind die Komponenten durch eigene
Ablaufplanungsstrategien, die simuliert werden müssen, gekennzeichnet.

\begin{figure}
\begin{center}
\includegraphics[width=12cm]{ib_vpc_framework}
\caption{Schema des VPC-Simulations-Framework. Tasks werden über einen
  zentralen Direktor den ausführenden Komponenten zugeordnet. Den einzelnen
  virtuellen Komponenten (VPC) können unterschiedliche Schedulingstrategien
  zugeordnet werden.}
\label{fig:vpc-framework-ueberblick}
\end{center}
\end{figure}

Für die Simulation des InfiniBand-HCA wurde dieses in 21 separate Prozesse 
zerlegt (vgl. Abbildung \ref{fig:hca_func_units_lib} auf Seite 
\pageref{fig:hca_func_units_lib} sowie Abbildung \ref{fig:hca_modules}  
auf Seite \pageref{fig:hca_modules}). Jeder dieser Prozesse stellt
einen Problemgraphknoten $v \in V_P$ dar.

Ein objektorientiertes Modell soll die Architektur für die Simulation
  abbilden. Jede Komponente\footnote{Knoten des
  Architekturgraphen $v \in V_A$.} wird durch ein eigenes Objekt repräsentiert. Ein
  \module{Scheduler}-Objekt wird einer Komponente zugeordnet und stellt die
  Ablaufplanung sicher. Eine zentrale Instanz zur Verwaltung (der Direktor)
  übernimmt die Aufgaben \emph{Bindung} und \emph{Allokation} der 
Komponenten. Eine
Übersicht findet sich im UML-Klassendiagramm in Abbildung
\ref{fig:vpcframework}.
\begin{figure}
\begin{center}
\includegraphics[width=14cm]{vpc-framework}
\caption{UML-Klassendiagramm des VPC-Frameworks.}
\label{fig:vpcframework}
\end{center}
\end{figure}


\subsection{Component}
Die \module{Component} ist die Zentrale Einheit des
Vir\-tu\-al-Pro\-cess\-ing-Com\-pone\-nts-Frame\-works. Daher folgt auch der Name des
Frameworks. 


Eine Komponente stellt die ausführende Umgebung für einen Prozess dar. Einen
Prozess an eine Ressource zu binden, führt zu unterschiedlichen Kosten oder
Bewertungen. Für die Systemsimulation sind
die Ausführungszeiten der Prozesse und somit die Latenz des Problems die
wichtigste Zielfunktion. Die Bindung eines Tasks an eine Komponente zieht also
unterschiedliche Ausführungszeiten und somit eine unterschiedliche Latenz nach 
sich.\footnote{Die einzelnen Ausführungszeiten eines Prozesses müssen für alle 
zur Ausführung in Frage kommenden Ressourcen bekannt sein, 
z.\,B. durch Schätzung.}

Die Ausführung eines Prozesses auf einer Ressource wird als eine funktional 
atomare Operation angesehen. Unterbrechungen durch Multitasking führen nicht
zu unterschiedlichem Verhalten, sondern nur zu verschiedenen Antwortzeiten der 
Prozesse. Dieses \emph{prozessakurate} Simulationskonzept ermöglicht einen geringen 
Simulationsaufwand. Trotzdem sind die Auswirkungen von Ressourcenbeschränkung 
und Schedulingstrategien auf die Latenz simulierbar. Dazu müssen den einzelnen 
Prozessen im Simulationsmodell Ausführungszeiten zugewiesen
werden. Erst nach Ablauf dieser Zeit stehen die Ausgangsdaten der Berechnung
bereit und folgende Module können aktiviert werden. SystemC bietet mit 
der \code{wait}-Funktion ein mächtiges Konzept zur Zeitmodellierung 
\cite{glms:2002}. Dieser Funktion wird die abzuwartende \emph{delay}-Zeit
übergeben. 




Unterschiedliche \emph{delay}-Zeiten werden wie folgt modelliert 
(vgl. Abbildung \ref{fig:task-component-compute}):
\begin{figure}
\begin{center}
\includegraphics[width=14cm]{task-component-compute}
\caption{Ausführungszeit in Abhängigkeit zur ausführenden Komponente. Die
  Ausführung von Task T2 auf Komponente 2 verursacht eine Ausführungszeit von
  20 ns.}
\label{fig:task-component-compute}
\end{center}
\end{figure}
Einem Prozess wird eine \module{Component}, analog zur Bindung,
zugewiesen. Die \module{Component} besitzt eine Schnittstelle, die
\code{compute}-Funktion, für den Zugriff von außen. Der aufrufende
Prozess übergibt der Funktion eine eindeutige Identifikation (numerisch
oder alphanumerisch). Durch den Aufruf von \code{wait} wird die dem Prozess
zugeordnete Wartezeit abgewartet. Anschließend kehrt die
\code{compute}-Funktion mit \code{return} zurück und der Prozess kann
die Berechnung fertig stellen. 


\subsection{Director}


Zur Bindung der Tasks auf die Ressourcen wird ein weiteres Objekt, der
\module{Director} verwendet. Wie ein Direktor im realen Leben ist er mit den
wesentlichen administrativen Aufgaben betreut. Der \module{Director} ist als
\emph{Singleton}-Entwurfsmuster realisiert. Also existiert nur eine Instanz
dieser Klasse.  Diese Instanz kann über die statische Funktion
\code{getInstance} abgerufen werden (vgl. Abbildung
\ref{fig:director_getinstance}). Nun kann die ausführende
\begin{figure}
\begin{center}
\includegraphics[width=10cm]{director_getinstance}
\caption{\module{Director} als \emph{Singleton}-Entwurfsmuster. Für den Zugriff
  auf die Singleton-Instanz wird eine statische Funktion bereitgestellt.}
\label{fig:director_getinstance}
\end{center}
\end{figure}
\module{Component} durch Aufruf von \code{getResource} auf dem
\module{Director}-Objekt ermittelt werden. Dabei muss eine Identifikation des
Problem-Moduls stattfinden. Es liegt nahe, diese analog zu der Identifikation
der \code{compute}-Funktion in der \module{Component} zu gestalten. Der gesamte
Mechanismus ermöglicht sowohl statische als auch dynamische Bindung der
Prozesse an die Komponenten. Nach dem Aufruf der \code{getResource} Funktion
steht die Bindung für den aufrufenden Prozess fest. Eine
\emph{Migration} von Prozessen d.\,h., die Unterbrechung eines Prozesses auf einer Ressource
und die Fortsetzung auf einer Anderen, ist nicht möglich. Bei einer erneuten
Aktivierung eines Prozesses ist sehr wohl eine andere Bindung möglich. 

\subsection{Ressourcen-Konfigurationsdatei}\label{resconfig}

Die zu verwendende Allokation und Bindung für eine Simulation wird in Form
einer Konfigurationsdatei vorgegeben und soll hier am Beispiel des 
InfiniBand-HCA vorgestellt werden. Eine Konfiguration besteht aus zwei 
Teilen, der Allokation gefolgt von der Bindung. Die Allokation wird durch 
das Schlüsselwort \code{component:} eingeleitet, gefolgt durch den Namen 
der Komponente und den zu verwendenden Scheduler. Der Scheduler kann dabei
weitere Parameter enthalten. Eine Bindung setzt sich aus dem Namen des 
Prozesses, der zu verwendenden Komponente, der Ausführungszeit (in Nanosekunden) und der 
Priorität\footnote{Wird nur für prioritätsbasiertes Scheduling 
ausgewertet.} des Prozesses zusammen. Als Trennzeichen werden ein oder 
mehr \emph{Whitespaces} erwartet. Ein Beispiel:\\
\begin{verbatim}
component:  HWM1  FCFS
component:  HWM2  RoundRobin:timeslice-200ns

sim_mod.h_hca.qpc_manager       HWM1 4000 50
sim_mod.h_hca.h_send_port       HWM1 1000 50
sim_mod.h_hca.h_transmit_queue  HWM2 2000 50
...
\end{verbatim}
In diesem Beispiel werden zwei Komponenten, \emph{HWM1} und \emph{HWM2},
verwendet. Die Ablaufplanung auf Ressource \emph{HWM1} unterliegt der
\emph{First-Come-First-Serve}-Stra\-te\-gie. Ein \emph{Round-Robin}-Verfahren
mit einer Zeitscheibe von 200 ns dient als Ablaufplanungsstrategie auf
Komponente \emph{HWM2}. An die Komponente 
\emph{HWM1} werden die Prozesse \emph{sim\_mod.h\_hca.qpc\_manager}
 und \emph{sim\_mod.h\_hca.h\_send\_port}  gebunden, ihre Ausführungszeiten betragen 4000
ns und 1000 ns. Auf der Ressource \emph{HWM2} wird der Prozess
\emph{sim\_mod.h\_hca.h\_transmit\_queue} ausgeführt, seine Aus\-führ\-ungs\-zeit beträgt
2000 ns. Alle drei Prozesse des Beispiels sind mit der gleichen Priorität 50 
anotiert. In der Zukunft soll diese Format durch ein universelleres 
XML-Format ersetzt werden.




\subsection{Scheduler}\label{scheduler}
Im Spezifikationsgraph stellen die Problemknoten die
Aktivitätsträger dar. Ressourcen sind durch
Architekturknoten modelliert. Diese Grundlage ergibt eine
Mehrprozessorarchitektur. Unter der Annahme, dass ein Prozess während seiner Laufzeit nicht von einer
Ressource zu einer anderen verschoben wird, lässt sich der Spezifikationsgraph durch
mehrere Einprozessorarchitekturen darstellen.\footnote{Diese Annahme trifft
  hier zu, da Prozesse die atomaren Ausführungseinheiten darstellen.} Alle
aktivierten Prozesse beginnen mit der Ausführung, die im Sinne der 
simulierten (SystemC) Zeit instantan und nebenläufig stattfindet. Durch den
Aufruf der \code{compute}-Funktion auf der zugewiesenen Komponente wird die
verbrauchte Zeit simuliert. Rufen mehrere Prozesse auf einer \module{Component}
die \code{compute}-Funktion auf, ist es Aufgabe des \module{Schedulers}, eine
Ablaufplanung für die Prozesse sicherzustellen.

Wird ein Prozess auf einer Komponente ausgeführt, so ist eine Blockade des
Prozesses auszuschließen.\footnote{Ebenfalls wegen der Atomarität der Prozesse.} Daher
 vereinfacht sich das Zustandsmodell aus Sicht
der Komponente auf die zwei Zustände \emph{Bereit} und
\emph{Rechnend}. Zusammen mit dem Berechnungsmodell des Problemgraphen ergibt
sich das hierarchische Thread-Zustands\-modell aus Abbildung
\ref{fig:vpc-zustandsmodell}.
\begin{figure}
\begin{center}
\includegraphics[width=10cm]{vpc-zustandmodell}
\caption{Thread-Zustandsmodell des VPC-Simulators.}
\label{fig:vpc-zustandsmodell}
\end{center}
\end{figure}

Die beiden grau hinterlegten Zustände unterscheiden blockierte von
nicht-block\-iert\-en Prozessen. Also solche Prozesse, die auf ihre
Vorgängerprozesse blockiert sind und jene, die gerade auf einer Komponente
\code{compute} aufrufen. Somit ist das Ereignis \msg{ready} äquivalent zum
Aufruf von \code{compute} und das Beenden der Funktion mit \code{return}
stellt das Ereignis \msg{block} dar. Die Unterscheidung zwischen
\emph{Rechnend}- und \emph{Bereit}-Zuständen auf einer Komponente ist Aufgabe
des \module{Schedulers}. 



Die Nebenläufigkeit der Problemgraphprozesse
führt zu mehrfachen parallelen Aufrufen der \code{compute}-Funktion einer
Komponente durch unterschiedliche Prozesse. Daher existieren mehrere
Instanzen der Funktion. Der Sequenzgraph in Abbildung
\ref{fig:sequenzgraph-compute} stellt dies dar.
\begin{figure}
\begin{center}
\includegraphics[width=8cm]{sequenzgraph-compute}
\caption{Mehrere Aufrufe führen zu mehreren Instanzen der \texttt{compute}-Funktion.}
\label{fig:sequenzgraph-compute}
\end{center}
\end{figure}
Dabei handelt es sich um quasi-parallele Ausführung\footnote{Jede dieser Instanzen
ist dem Kontext des aufrufenden Problemknoten zugeordnet.}, die Umschaltung erfolgt
durch das SystemC-Modell. Diese Parallelität  ermöglicht letztendlich die Simulation
von Ablaufplanungsstrategien. Eine detaillierte Beschreibung bezüglich der
Scheduling-Simulation findet sich in \cite{vpc:2005}.



Der durch die Simulation entstandene Ablaufplan wird aufgezeichnet und 
kann mit Hilfe von Wave-Form-Viewern visualisiert werden.\footnote{Die 
Aufzeichnung erfolgt im \emph{VCD}-Format (\emph{Value Change Dump}).}
Dabei wird für jede Ressource eine Datei erzeugt, z.\,B.
\file{HCA1-HWM1.vcd}. Ein Signal, in solch einer Datei, repräsentiert 
einen Prozess, welcher auf der entsprechenden Ressource gebunden ist. 
Der Typ des Signals ist \code{char}, wobei die Zeichen 'R', 'w', 'b'
die Zustände \emph{Rechnend}, \emph{Bereit}, \emph{Blockiert} 
repräsentieren. Ein Beispiel eines
Ablaufplans für die InfiniBand-HCA-Simulation mit vier Komponenten im 
VPC-Framework zeigt Abbildung \ref{fig:trace}

\begin{figure}
\begin{center}
\includegraphics[width=14cm]{infiniband-mixed-mixed-trace}
\caption{\emph{Trace file} der InfiniBand-HCA-Simulation unter Einsatz von vier Komponenten.}%%TODO verbessern
\label{fig:trace}
\end{center}
\end{figure}


\section{Simulator-Synchronisation}
\label{sec:Simulator-Synchronisation}
Die oben vorgestellten Mechanismen dienen dazu, jedem Prozess eine 
Aus\-füh\-rungs\-zeit in Abhängigkeit zur Bindung und Schedulingstrategie 
zuzuordnen. Die Zeitmodellierung verwendet hierbei die 
Mechanismen von SystemC. Die Auftrennung in zwei 
kommunizierende InfiniBand-HCA-Simulationen, wie in Kapitel 
\ref{cha:ib_sim_model} vorgestellt, erweist sich jedoch als Problem
für eine solche ereignisorientierte Zeitsimulation. Der folgende Abschnitt
wird dieses Problem erläutern und die implementierte Lösung 
vorstellen. Zunächst jedoch wird das Prinzip der ereignisorientierten Simulation
er\-läut\-ert.

%%\subsubsection{Ereignisorientierte Simulation}
Die ereignisorientierte Simulation ist dadurch gekennzeichnet, dass der
Simulator nur dann in Aktion tritt, wenn eine Änderung (Event) stattgefunden hat. Anstatt
sich von Zeitschritt $i$ zu Zeitschritt $i+1$ zu hangeln, springt der 
Simulator von einem Event zum (im Zeitverlauf) nächsten Event. Gleichzeitig
schreitet die simulierte Zeit um diese Differenz voran. Folglich kann die
Zeitauflösung groß gewählt werden, ohne zusätzliche Aktivierungen des
Simulators auszulösen. Beispiele für ereignisorientierte Simulation finden 
sich z.\,B. bei der Simulation von VHDL- oder SystemC-Code \cite{glms:2002, sysc1}. 

Eine Liste mit offenen (noch nicht bearbeiteten) Ereignissen ist das Zentrum der
ereignisgetriebenen Simulation \cite {cassandras:1993}. Das Ereignis, welches am nächsten in der Zukunft
liegt, wird ausgewählt, abgearbeitet und die Simulationszeit wird
aktualisiert. Bei der Abarbeitung des Vorgangs (Prozesses), welches dem Event
zugeordnet ist, können neue Ereignisse samt Auftrittszeitpunkt generiert und
in die Ereignisliste eingetragen werden. Soll aufgrund einer Aktivität ein weiterer
Vorgang zum gleichen Zeitpunkt aktiviert werden, wird ein entsprechendes Event
mit gleichem Zeitindex generiert. Derartig erzeugte Ereignisse werden in
unterschiedlichen \emph{Delta-Zyklen} abgearbeitet. Somit wird die mehrfache
Aktivierung eines Events zum gleichen Zeitpunkt, aber in unterschiedlichen
Delta-Zyklen möglich. Ein zu häufiges Auftreten von Ereignissen kann die
Simulation nachteilig beeinflussen. Bei der zeitorientierten Simulation wird
jeder kleinste Zeitschritt nur einmal bewertet, die Delta-Zyklen der
ereignisorientierten Simulation machen unter
Umständen eine mehrfache Betrachtung des gleichen Zeitpunktes notwendig.

Dieses Simulationskonzept führt dazu, dass die Zeit nicht Schritt für Schritt
voranschreitet, sondern in verschieden großen Schritten. Bei der Zusammenschaltung der
beiden InfiniBand-HCA-Simulatoren würde jede Simulatorinstanz nur ihre eigene 
Zeitlinie betrachten. Wenn ein Simulator ein Datenpaket zu einem Zeitpunkt an den
anderen Simulator schickt ist nicht gewährleistet, dass es dort zum gleichen Zeitpunkt
ankommt. Sollte die Sendezeit in der Zukunft liegen, wäre dieses Problem durch 
warten auf der Empfangsseite zu lösen. Liegt die Sendezeit dagegen in der Vergangenheit
des empfangenden Simulators kann die Zeit nicht zurückgedreht werden.

Folgendes Beispiel soll die Problematik verdeutlichen: Simulator HCA-1 und Simulator HCA-2 
starten zum gleichen Zeitpunkt (sowohl gleiche Simulationszeit, als auch gleiche 
Ausführungszeit). Einer der beiden, in diesem Fall HCA-1, soll eine Reihe von Anfragen
abarbeiten, dabei werden Datenpakete erzeugt und zum HCA-2 gesendet. HCA-2 hat 
gerade nichts  zu tun und soll erst zu einem späteren Zeitpunkt eine Consumer-Anfrage
abarbeiten. Die ereignisgesteuerte Simulation sorgt dafür, dass zu dem 
Zeitpunkt vorwärts gesprungen wird, an dem weiter gearbeitet werden kann. Wegen der 
starken Aktivität im HCA-1 wird die Zeit nur in kleinen Schritten, gefolgt 
von Simulatoraktivität, weitergeschaltet. Im HCA-2 findet ein großer Sprung
in die Zukunft statt. Nun erzeugt der HCA-1 nach einigen Berechnungsschritten 
ein Datenpaket für den HCA-2, dieses kommt dort jedoch in der Vergangenheit an.

Dieses Problem resultiert aus der \emph{verteilten Event-Queue} der getrennten
Simulatoren. Mögliche Ansätze, dieses Problem zu lösen, sind:
\begin{itemize}
\item Keine Trennung der beiden Simulationen (Gemeinsame Event-Queue).
\item Anpassung des SystemC Quellcodes, um verteilte Event-Queues zu unterstützen.
\item Aufgabe der Ereignisorientierten Simulation.
\end{itemize}

Die Trennung der Simulation in zwei Instanzen ermöglicht Tests über Rechnergrenzen
hinweg. Und somit auch die Möglichkeit, einen Simulator gegen eine Hardwareimplementierung
zu testen. Eine gemeinsame Simulation würde diese Eigenschaften zerstören. 

Eine Anpassung der SystemC-Bibliothek benötigt einen direkten Eingriff in den 
Quellcode. Dies führt zur Inkompatibilität der InfiniBand-HCA-Simulation mit anderen 
SystemC-Installationen. Das Kosten-Nutzen-Verhältnis steht dann, auch 
wegen dem Implementierungsaufwand, in einem nicht tragbaren Verhältnis.

Bleibt als letzte Lösung die Aufgabe der ereignisorientierten 
Simulation: In jeder Simulation läuft ein Prozess, der in einem festen 
Simulationszeitintervall die Simulationen synchronisiert. Um das Auseinanderdriften
zu verhindern, sollte dieses Intervall möglichst klein sein. Eine solche Umsetzung 
hat nun wiederum den Effekt, dass die Vorteile der ereignisorientierten  
Simulation verloren gehen. Zusätzlich kombiniert man die Nachteile von 
ereignisorientierter und zeitorientierter Simulation. Wegen der Synchronisation 
wird jeder Zeitschritt simuliert und wegen der zu Grunde liegenden ereignisorientierten
Simulation, bleibt die mehrfache Betrachtung des selben Zeitschrittes in verschiedenen
Delta-Zyklen erhalten.



Diese Nachteile können abgeschwächt werden, wenn für die Kommunikation zwischen
den InfiniBand-HCA-Simulatoren eine Verzögerungszeit angenommen wird. Diese hier implementierte
Variante funktioniert dann wie folgt: Ein Simulator HCA-1 erzeugt zu einem Zeitpunkt 
ein Datenpaket, dieses Paket wird mit einem Zeitstempel versehen. Dieser Zeitstempel
setzt sich aus der Simulationszeit von HCA-1 und der Kanalverzögerung zusammen. Der
zweite Simulator, HCA-2, empfängt dieses Paket und erkennt, zu welchem Zeitpunkt dieses
Paket bei ihm ankommen muss. Aufgrund des Wissens, dass HCA-1 neue Pakete frühestens zum selben
oder zu späteren Zeiten produzieren könnte, kann sich der paketlesende Prozess
bis zu dieser Zeit blockieren. Während dieser Blockade können die anderen Prozesse der 
Simulation arbeiten. Dies ist damit zu vergleichen, dass die Simulatoren sich gegenseitig 
Zeit ``schenken''\footnote{Wegen der Verzögerung kann garantiert werden, dass eine Simulation
keine Aktivitäten bei der anderen auslöst.}, um zu arbeiten (vgl. 
Abbildung \ref{fig:zeitfluss}). Da nicht ständig Pakete 
gesendet werden können und somit keine Zeit garantiert werden kann, müssen sich die 
Simulationen immer wieder Pseudo-Pakete zusenden, um sich gegenseitig Zeit zu 
``schenken''. 

\begin{figure}
\begin{center}
\includegraphics[width=10cm]{zeitfluss}
\caption{Datenpakete werden zu einem Zeitpunkt gesendet, kommen sofort an, werden aber erst
nach der Kanalverzögerung gültig (empfangen). Diese Zeitspanne kann die gegenüberliegende
Simulation unabhängig arbeiten, sie bekommt Zeit ``geschenkt''.}
\label{fig:zeitfluss}
\end{center}
\end{figure}

In der Implementierung sieht dies wie folgt aus: Auf dem Kanal zwischen den Simulationen
werden Pakete versendet. Diese Pakete bestehen aus einem Header und dem eigentlichen
Datenpaket. Der Header enthält die Größe des Datenpakets und den Typ der Daten. Zur 
Zeit existieren zwei Typen: 
\begin{description}
\item[ib\_packet:] Ein echtes Datenpaket (Bytearray), das zwischen den Simulationen
ausgetauscht wird.
\item[timestamp:] Ein Zeitstempelpaket, welches dazu dient, dem Empfänger Zeit zu garantieren.
\end{description}
Vor jedem  ib\_packet wird ein Zeitstempelpaket versendet, welches die Ankunftszeit des
Paketes spezifiziert. Wird in einem festen Zeitraum kein ib\_packet versendet, so wird
provisorisch ein Zeitstempelpaket versendet und somit der anderen Simulation Zeit 
``geschenkt''. Dieser feste Zeitraum muss kleiner gleich der Kanalverzögerung sein, um einen
Deadlock zu vermeiden. Weiterhin ist es notwendig, dass die Simulationen beim Starten sich als
erstes einen Zeitstempel zusenden, damit die Simulation starten kann.

